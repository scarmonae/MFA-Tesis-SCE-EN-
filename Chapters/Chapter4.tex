\chapter{Optical Characterization}

\noindent This chapter details the materials and methods used for the development of this work. Initially, the materials employed are described, including specific equipment, light sources, calibration patterns, and software used for data acquisition, processing, and analysis.\\

\noindent Subsequently, the experimental methods are presented, organized according to the type of measurement performed: geometric and spectral measurements. For each method, the experimental procedure is clearly described, justifying the choice of technique and specifying the conditions under which the experiments were conducted, including details of instrument configuration and protocols followed.\\


% Finalmente, se incluye una breve descripción de los resultados esperados tras la ejecución de los métodos mencionados, acompañada del cronograma previsto para las actividades y el presupuesto estimado requerido para la implementación del estudio. Esta información busca proporcionar claridad y facilitar la replicabilidad del estudio, así como sustentar la factibilidad y pertinencia metodológica del proyecto.


% \section{Parámetros Espectrales para la Determinación de Índices de Vegetación}

% Para una caracterización efectiva y la calibración de cámaras multiespectrales destinadas a la medición de índices de vegetación, es crucial considerar los siguientes parámetros espectrales:

% \subsection{Sensibilidad Espectral del Sensor}
% \begin{itemize}
%     \item \textbf{Rango Espectral}: Define las longitudes de onda a las que el sensor es sensible. Para la mayoría de las aplicaciones en vegetación, es esencial cubrir desde el espectro visible (400-700 nm) hasta el infrarrojo cercano (700-1100 nm). Esta sensibilidad permite la detección precisa de la reflectancia de la vegetación, lo cual es crítico para índices como el NDVI \cite{Huang2021ASensing}.
%     \item \textbf{Sensibilidad Relativa}: Mide la respuesta del sensor a diferentes longitudes de onda dentro del rango espectral. La sensibilidad relativa determina qué tan bien el sensor puede diferenciar entre diversas características de la vegetación basándose en sus firmas espectrales \cite{Dale2013HyperspectralReview, Klein2011MethodsCameras}.
% \end{itemize}

% \subsection{Transmisión Espectral del Objetivo (Lente)}
% \begin{itemize}
%     \item \textbf{Coeficiente de Transmisión Espectral}: Este parámetro describe la proporción de luz transmitida a través del objetivo en función de la longitud de onda. Es fundamental evaluar cómo los objetivos afectan la intensidad y calidad de la luz que llega al sensor para evitar distorsiones espectrales que puedan afectar la precisión de los índices de vegetación \cite{Xue2017SignificantApplications}.
%     \item \textbf{Rango de Transmisión Espectral}: El objetivo debe permitir la transmisión efectiva de las longitudes de onda relevantes (por ejemplo, bandas roja e infrarroja cercana) utilizadas para el cálculo de índices de vegetación. El rango de transmisión afecta directamente la calidad de la señal recibida por el sensor \cite{Dale2013HyperspectralReview}.
% \end{itemize}

% \subsection{Características Espectrales del Filtro}
% \begin{itemize}
%     \item \textbf{Curva de Transmitancia Espectral}: Define cómo el filtro permite o bloquea diferentes longitudes de onda. Es esencial para asegurar que sólo las longitudes de onda deseadas alcancen el sensor, eliminando posibles interferencias de otras bandas espectrales \cite{Huang2021ASensing}.
%     \item \textbf{Longitud de Onda de Corte y Ancho de Banda de Transmisión}: La longitud de onda de corte indica el punto donde el filtro comienza a bloquear la luz, mientras que el ancho de banda de transmisión especifica el rango de longitudes de onda que el filtro permite pasar. Estos parámetros son clave para seleccionar y diferenciar bandas espectrales específicas necesarias para índices de vegetación \cite{Dale2013HyperspectralReview}.
% \end{itemize}

% \subsection{Respuesta Espectral Combinada del Sistema}
% \begin{itemize}
%     \item \textbf{Eficiencia Espectral Total}: Considera la eficiencia combinada de sensor, objetivo y filtro para captar la luz en las longitudes de onda relevantes. Esto incluye la integración de todas las respuestas espectrales de los componentes individuales para determinar la capacidad del sistema completo en la detección y medición de índices de vegetación \cite{Xue2017SignificantApplications}.
%     \item \textbf{Linealidad y Estabilidad Espectral}: Evalúa cómo se mantiene la respuesta espectral del sistema bajo diferentes condiciones de iluminación y ambientales. La estabilidad espectral es crítica para aplicaciones en campo donde las condiciones pueden variar significativamente \cite{Dale2013HyperspectralReview}.
% \end{itemize}

% Estos parámetros deben ser cuidadosamente caracterizados y calibrados para asegurar que la cámara multiespectral proporcione datos precisos y fiables para la medición de índices de vegetación, facilitando así aplicaciones como el monitoreo de la salud de los cultivos, la evaluación del estrés vegetal y el análisis de cambios en la cobertura vegetal.


\section{Geometric Characterization}

\subsection{Determination of Field of View (FOV) and Angular Field of View (AFOV)}
\label{sec:fov}


\noindent The Field of View (FOV) of the optical system is determined in order to assess the maximum ground area that can be observed by the system, depending on the distance between the optical system and the surface. For this, an optical setup is conducted in a laboratory to measure the FOV as the distance varies. The optical setup is shown in Figure~\ref{fig:MTF_FOV_montage}. First, a test chart is placed on a stable base located on an optical bench, preferably using a clamp that allows proper orientation with respect to the optical axis of the system. In this case, the test chart used is an ISO-12233 spatial frequency response test chart that comes with multiple sensor format sizes, including an option for a 4:3 sensor aspect ratio. The reason for selecting this pattern is that it contains multiple elements whose length and distance between them can be measured, which allows and facilitates varying the working distance between the optical system being characterized and the chart, such that the edges of the captured image align with a pair of elements in the pattern. It is essential that the chart is properly positioned, centered, and perpendicular to the system's optical axis to minimize errors caused by tilts or misalignments. Next, the optical system is positioned on its corresponding base on the optical bench, ensuring it is centered and properly aligned with the test film.\\ 

\noindent Once the initial setup is established, images of the film are captured at different working distances. During image acquisition, an effort is made to precisely align the visible edges of the image with a known edge on the test film. Measurements are taken strictly in the vertical or horizontal direction, explicitly measuring the distance between objects located at opposite edges of the image. This procedure is carried out for both the horizontal and vertical FOV, as they may differ depending on the format of the optical sensor. In this case, The sensor used in this setup captures images with a 4:3 aspect ratio, which is typical for many scientific and industrial cameras. 


\begin{figure}[H]
        \centering
        \includegraphics[width=0.98\linewidth]{Figures/C3/MTF_montaje.pdf}
        \caption{Optical setup developed. The test chart used is an ISO-12233 spatial frequency response test chart printed in mate paper with a size of 69 $\times$ 42 cm. In this case, the use of barriers to prevent capture of unwanted light directly from the illumination source was not necessary, as the source is located behind the optical system under test. The illumination source is a tungsten halogen lamp coupled with a fiber optic cable and a diffuser.}
        \label{fig:MTF_FOV_montage}
\end{figure}


\noindent
Before analysing the experimental data it is useful to establish the theoretical dependence of FOV on distance. In an ideal image-forming optical system, the linear relationship between the field of view (FOV) and the working distance arises from basic geometric optics. Under the pinhole camera model, the scene geometry is projected through a central projection point (the pinhole), forming a similar triangle between the object field and the sensor plane \cite{Hecht2002Optics,StanfordPinhole}. If the sensor has width $H$ and the lens has focal length $f$, the angular field of view (AFOV) is defined as:

\begin{equation}
\text{AFOV} = 2 \cdot \arctan\left(\frac{H}{2f}\right).
\end{equation}

\noindent
At a working distance $d$, the linear field of view on the object side is then given by:

\begin{equation}
\text{FOV}(d) = 2 \cdot d \cdot \tan\left(\frac{\text{AFOV}}{2}\right),
\label{eq:fov_linear}
\end{equation}

\noindent
This expression implies a direct proportionality between FOV and $d$, since $\tan(\text{AFOV}/2)$ is constant for a fixed sensor and focal length. For small angles ($\leq 30^\circ$), the tangent can be approximated as:

\begin{equation}
\tan\left(\frac{\text{AFOV}}{2}\right) \approx \frac{H}{2f},
\end{equation}

\noindent
yielding the simplified linear relationship:

\begin{equation}
\text{FOV}(d) \approx \frac{H}{f} \cdot d.
\end{equation}

\noindent
Thus, the rate of change of the FOV with respect to the working distance is constant and given by:

\begin{equation}
\frac{d\,\text{FOV}}{d\,d} = \frac{H}{f},
\end{equation}

\noindent
which is the linear magnification per unit distance. This linear approximation remains valid for small to moderate AFOV values, and forms the theoretical basis for modeling the FOV as a linear function of working distance in this study \cite{Hecht2002Optics}.\\


\noindent Since FOV measurements have inherent uncertainties due to the measuring instrument and other experimental sources, a statistical analysis using weighted linear regression is implemented to properly model the functional relationship between the measured FOV and the working distance. This method explicitly considers errors in both the dependent and independent variables, allowing for consistent and less biased estimates of the model parameters. The weighted linear regression is fitted using total least squares (Deming regression), which simultaneously minimizes deviations in both variables:

\begin{equation}
\text{FOV} = \beta_1 \cdot \text{Working distance} + \beta_0,
\label{eq:regresion_lineal}
\end{equation}

\noindent where $\beta_1$ is the slope and $\beta_0$ is the intercept, both calculated along with their associated uncertainties, thus ensuring a statistically reliable model to describe the behavior of the FOV as a function of working distance.\\

\noindent Unlike ordinary least squares (OLS) regression, which assumes uncertainty only in the dependent variable, Deming regression ---also known as total least squares regression--- accounts for errors in both variables by minimizing the orthogonal deviations from the data points to the fitted line \cite{Deming1943ErrorsInVariables}. In this study, this method was adopted since both the working distance and the field of view (FOV) were measured experimentally using instruments with finite resolution (a tape measure and a millimeter ruler), which introduce measurement uncertainties of approximately \SI{1}{\milli\meter} in both variables. \\

\noindent Deming regression requires specifying a variance ratio $\delta = \sigma_y^2 / \sigma_x^2$ between the errors in the two variables. In this case, since both uncertainties are comparable, we adopt $\delta=1$. Under this assumption, the coefficients of the fitted linear model $y = \beta_1 x + \beta_0$ are calculated as:

\begin{equation}
\hat{\beta}_1 = \frac{s_{yy} - s_{xx} + \sqrt{(s_{yy} - s_{xx})^2 + 4s_{xy}^2}}{2s_{xy}},
\end{equation}

\noindent where $s_{xx}$ and $s_{yy}$ are the sample variances of $x$ (working distance) and $y$ (FOV), and $s_{xy}$ is their covariance. The intercept is then computed as:

\begin{equation}
\hat{\beta}_0 = \bar{y} - \hat{\beta}_1\,\bar{x},
\end{equation}

\noindent ensuring that the fitted line passes through the centroid of the data.\\


\noindent This fitting methodology, by explicitly incorporating uncertainties in both axes, offers a statistically robust foundation for modeling experimental variability and strengthens the validity of the linear model used for geometric characterization of the optical system.\\


\noindent To minimize errors introduced by optical aberrations, such as spherical aberration, the measurements are preferably taken along the central horizontal and vertical axis of the image.\\

\noindent Regarding the system's focusing, it is recommended to use an autofocus mechanism for proper image acquisition of the test chart. Since the optical systems used in this study have a fixed focal length, the focus must be manually adjusted to obtain a high-quality image for each working distance of each observation. To optimize this adjustment, a method is used based on capturing an image of a well-defined edge, from which the corresponding intensity profile is extracted and displayed in real-time, in this case along the central horizontal line. The derivative of this profile is then calculated and plotted to represent the intensity variation across the edge transition. Focus optimization is achieved by maximizing the prominence of the peak in the derivative, indicating a higher definition in the signal variation. This point of maximum variation is considered indicative of correct focus. Figure~\ref{fig:enfoque_conjunta} shows a representative example of optimal edge focusing.\\

\begin{figure}[H]
    \centering
    % First subfigure
    \begin{subfigure}[b]{0.7\linewidth}
        \centering
        \includegraphics[trim=0mm 0mm 0mm 10mm, clip, width=\linewidth]{Figures/C3/SE_1.png}
        \caption{Edge image used for manual focusing.}
        \label{fig:enfoque}
    \end{subfigure}
    
    \vspace{1em} % Vertical space between subfigures

    % Second subfigure
    \begin{subfigure}[b]{0.95\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/C3/SE_signal.png}
        \caption{Intensity profile extracted along the central horizontal line of the edge image.}
        \label{fig:se_signal}
    \end{subfigure}
    
    \vspace{1em} % Vertical space between subfigures

    % Third subfigure
    \begin{subfigure}[b]{0.95\linewidth}
        \centering
        \includegraphics[width=\linewidth]{Figures/C3/SE_diff.png}
        \caption{Derivative of the intensity profile; the maximum peak height is used as the focus metric.}
        \label{fig:se_diff}
    \end{subfigure}
    
    \caption{Set of images used for focus optimisation: (a) raw edge image, (b) corresponding intensity profile, and (c) derivative of that profile. The optimum focus position is identified when the derivative peak in (c) reaches its maximum amplitude, indicating the sharpest edge transition.}
    \label{fig:enfoque_conjunta}
\end{figure}


\subsection{Modulation Transfer Function (MTF) Characterization}
\label{sec:mtf_char}
The Modulation Transfer Function (MTF) enables an objective evaluation of the optical system’s ability to reproduce detail and contrast at different spatial frequencies. In this work, the slanted-edge method is used, as established by the international standard ISO 12233, which offers high precision, repeatability, and reliability.

The procedure begins by placing the ISO 12233 standard spatial resolution chart (see Figure~\ref{fig:iso12233_test_chart}) on a stable base. Uniform illumination over the chart’s surface is ensured, guaranteeing that the light intensity at any point does not vary more than $\pm 10\%$ from the center value. To prevent direct light from hitting the optical system, barriers are installed to block any undesired light.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{Figures/C3/ISO_12233-reschart.pdf}
    \caption{Standard chart used to measure the spatial frequency response of the optical system, as established in the ISO 12233 standard.}
    \label{fig:iso12233_test_chart}
\end{figure}

Since the optical system under analysis does not have autofocus and instead requires manual adjustment, a Python script was implemented to display the camera or sensor image in real time, along with a window showing the central horizontal intensity profile and another window showing its derivative. To determine optimal focus, the method seeks to maximize the magnitude of the extreme values—peaks and valleys—of the derivative of the central profile, since a higher derivative corresponds to better edge resolution. This indicates that the focus point has been reached where high spatial frequency details are best reproduced. This method is the same as described in Section~\ref{sec:fov}.\\

The aperture and exposure time of the optical system are carefully adjusted to obtain a maximum signal without saturation in the bright areas of the target. Signal clipping must be avoided in both bright and dark regions, including the transition zones of the slanted edge. As image compression can significantly affect resolution measurements, all system settings must be recorded and reported, including focal length, aperture, sensor resolution, and compression modes used. When using color cameras, proper white balance must be applied according to the light source, as specified in ISO 14525. White balance may be performed automatically if the software and optical system support it, or manually using the RGB channel histogram. The goal is to overlap the histogram peaks of the three channels as much as possible. For this work, white balance was performed manually, ensuring that the peaks corresponding to the bright zone overlap across the three RGB channels. This signal distribution can be seen in Figure~\ref{fig:illumination_distribution}.\\

The MTF measurement is carried out following the steps outlined below:

\begin{enumerate}
    \item The illumination is configured as shown in Figure~\ref{fig:srf_motaje}. Ambient lighting must be reduced to a minimum. If necessary, a diffuser should be used to ensure the illumination is as homogeneous as possible and to avoid unwanted intensity patterns from the light source.
    
    \begin{figure}[H]
        \centering
        \includegraphics[trim=20mm 50mm 20mm 0mm, clip, width=0.7\linewidth]{Figures/C3/iso 12233 montaje.png}
        \caption{Optical setup recommended by ISO 12233:2024 for accurate MTF measurement. (1) matte black background, (2) test chart, (3) white illumination, (4) optical system under test, (5) barriers to prevent direct illumination of the optical system, (6) adjustable working distance.}
        \label{fig:srf_motaje}
    \end{figure}

    \item The illumination is arranged such that the signal distribution delivered by the optical system is as homogeneous as possible. This implies that the captured image should show two well-defined peaks: one for the dark areas and another for the bright areas of the test pattern. Ideally, these peaks would be delta functions, indicating sharp transitions between intensity regions. In practice, secondary peaks should be minimized and the main peaks should be as narrow as possible. A homogeneous distribution ensures the optical system’s response is measured under controlled conditions and the MTF analysis is not affected by unwanted illumination variations. Figure~\ref{fig:illumination_distribution} shows the distribution achieved for the region of interest shown in Figure~\ref{fig:enfoque}. Additionally, this distribution confirms that signal saturation is minimal in the region of interest.

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{Figures/C3/Histogram_MTF.pdf}
        \caption{Signal distribution delivered by the optical system under the configured experimental illumination. Two main peaks are observed: one in the dark zone and another in the bright zone, with attenuated secondary peaks.}
        \label{fig:illumination_distribution}
    \end{figure}

    \item The optical system is positioned to properly frame the test chart. Vertical arrows help adjust magnification, while horizontal arrows assist in centering the image. The tips of the central black arrows should be fully visible, while the white arrows should be completely hidden. The horizontal edge of the chart should be aligned approximately parallel to the sensor’s horizontal lines. The approximate distance between the camera and the test chart is recorded for later analysis. Figure~\ref{fig:iso12233_test_chart_encuadre} shows the arrows used for alignment.

    \begin{figure}[H]
        \centering
        \includegraphics[width=0.8\linewidth]{Figures/C3/ISO_12233-reschart_arrows.png}
        \caption{Standard chart used to measure the spatial frequency response of the optical system. The arrows used for framing and camera alignment are highlighted.}
        \label{fig:iso12233_test_chart_encuadre}
    \end{figure}

    \item The chart is carefully rotated at an angle between $2^\circ$ and $10^\circ$ relative to the sensor’s pixel rows or columns to ensure accuracy in the MTF determination. The chart shown in Figure~\ref{fig:iso12233_test_chart} includes slanted edge patterns that meet this angular requirement.

    \item 50 images of the slanted edge are captured and averaged to reduce temporal noise and improve statistical quality.

    \item 50 dark images are also captured and averaged for sensor non-uniformity correction. This correction is detailed in Section~\ref{subsub:corriente_oscura_espectrometro}.

    \item The slanted edge image is corrected using the previously obtained average dark image.

    \item A specific analysis region is selected within the corrected image, where the slanted edge is clearly distinguishable.

    \item The exact angle of the slanted edge with respect to the sensor rows or columns is determined in order to properly normalize spatial frequency for MTF analysis.

    \item The Edge Spread Function (ESF) is obtained by analyzing pixel intensity values across multiple rows or columns crossing the slanted edge.

    \item To enhance method precision, oversampling is performed by combining multiple rows or columns (at least four) to generate a single, more accurate spatial function.

    \item The ESF is numerically differentiated to generate the Line Spread Function (LSF).

    \item Finally, the Fast Fourier Transform (FFT) is applied to the LSF to obtain the MTF:

    \begin{equation}
        \text{MTF}(f) = \left|\mathcal{F}\{\text{LSF}(x)\}(f)\right|,
    \end{equation}

    where $\mathcal{F}$ denotes the Fourier transform operation and $f$ is the spatial frequency.

    \item The resulting MTF curve is normalized to its maximum value at low frequencies and plotted against spatial frequency for analysis.
\end{enumerate}

MTF processing is performed using the \href{https://imagej.net/ij/plugins/se-mtf/index.html}{SE\_MTF} plugin from \href{https://imagej.net/ij/index.html}{ImageJ}. In this procedure, the image scale is configured in physical units (e.g., lp/mm) based on the actual sensor size and number of photodetectors. Once parameters are configured, the plugin extracts the Edge Spread Function (ESF) from the image edge and, through numerical differentiation, generates the Line Spread Function (LSF). Then, a Fast Fourier Transform (FFT) is applied to the LSF to obtain the Modulation Transfer Function (MTF).

Figure~\ref{fig:plugin_config1} shows the interface for configuring parameters. Based on the Region of Interest (ROI) and pixel size, it is possible to compute the required parameters for plugin configuration.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\linewidth]{Figures/C3/imagej_conf.png}
    \caption{Configuration screen of the SE\_MTF plugin in ImageJ. Setup for a Region of Interest of 104 $\times$ 104 pixels and a pixel size of 2.2 $\mu \text{m}$.}
    \label{fig:plugin_config1}
\end{figure}

\subsubsection{Ground–Resolved Distance (GRD) Derived from the MTF}
\label{subsub:grd_from_mtf}

The Modulation Transfer Function provides a frequency–domain representation of the
optical system’s ability to reproduce scene detail.  To translate the laboratory MTF into a
practical “ground” resolution (often called the \emph{ground‑resolved distance}, GRD), the
following procedure is applied\footnote{The workflow follows the recommendations of
ISO~12233 and common practice in remote‑sensing optics
\cite{Boreman2001MTF, Holst2008Electro‑Optical}.}.

\paragraph{1. Identify the cut–off spatial frequency in the image plane.}
From the measured MTF curve, the spatial frequency
$f_{\text{im}}$ (in line‑pairs per millimetre, lp/mm) at which the modulation falls to
30\,\% is chosen as the \emph{cut‑off} frequency:
%
\begin{equation}
    \text{MTF}\bigl(f_{\text{im}}\bigr)=0.30.
    \label{eq:mtf_cutoff}
\end{equation}

\paragraph{2. Convert to object‑space frequency.}
The primary lateral magnification\footnote{For object distances
much larger than the focal length, the primary magnification
$\text{PMAG}$ is well approximated by
$\text{PMAG}= \dfrac{\text{Horizontal Sensor Size}}{\text{FOV}}$;
see Eq.~(\ref{eq:res_0}).} of the lens is
%
\begin{equation}
    \label{eq:pmag}
    \text{PMAG}= \frac{\text{Horizontal Sensor Size}}{\text{FOV}}.
\end{equation}
%
The corresponding frequency in object space is therefore
%
\begin{equation}
    f_{\text{obj}} = f_{\text{im}} \times \text{PMAG}
    \quad\left[\frac{\text{lp}}{\text{mm}}\right].
    \label{eq:f_obj}
\end{equation}

\paragraph{3. Compute the linear ground‑resolved distance.}
A line pair consists of one dark and one bright line; hence the minimum
distinguishable physical period on the ground, expressed in micrometres, is
%
\begin{equation}
    \Delta_{\text{ground}} =
    \frac{1}{2\,f_{\text{obj}}}\;\times\;
    \frac{1000\;\mu\text{m}}{1\;\text{mm}}.
    \label{eq:delta_ground}
\end{equation}
%
If a specific flight altitude (working distance) $\text{WD}$ is assumed, the
same result can be expressed directly in metres by multiplying
Eq.~(\ref{eq:delta_ground}) by the scale factor
$\dfrac{\text{WD}}{\text{focal length}}$, yielding the \emph{ground sample
distance} (GSD).

\paragraph{4. Reporting.}
For every lens/sensor pair characterised in
Section~\ref{sec:fov}--\ref{subsub:grd_from_mtf},
Table~\ref{tab:grd_results} lists
$f_{\text{im}}$ at 30\,\% contrast, the computed $f_{\text{obj}}$, and the resulting
$\Delta_{\text{ground}}$ for the three mission altitudes analysed
(50\,m, 1000\,m, and 5000\,m).

\begin{table}[h]
    \centering
    \caption{Ground‑resolved distance (GRD) derived from the 30 \%‑contrast MTF cut‑off. 
             Placeholder numbers are shown; replace them with the values measured for
             each optical system.}
    \label{tab:grd_results}
    \begin{tabularx}{\linewidth}{|l|C|C|C|C|C|}
        \hline
        \rowcolor[HTML]{EFEFEF}
        \textbf{System} & 
        $f_{\text{im}}$ [lp/mm] & 
        $f_{\text{obj}}$ [lp/mm] & 
        GRD @50\,m [cm] & 
        GRD @1000\,m [m] &
        GRD @5000\,m [m] \\
        \hline
        VIS & - & - & - & - & - \\
        NIR & - & - & - & - & - \\
        \hline
    \end{tabularx}
\end{table}


\subsection{Acquisition Settings for VIS and NIR Systems}

The accuracy of resolution and MTF measurements largely depends on the optical system configuration during image capture. In this study, all configurations used for each system were recorded and reported. The following tables summarize the parameters used for the VIS system (visible spectrum camera) and for the NIR system (near-infrared camera):

\begin{longtable}[c]{c|cc|cc}
\hline
\rowcolor[HTML]{EFEFEF} 
\cellcolor[HTML]{EFEFEF} &
  \multicolumn{2}{c|}{\cellcolor[HTML]{EFEFEF}\textbf{FOV}} &
  \multicolumn{2}{c}{\cellcolor[HTML]{EFEFEF}\textbf{MTF}} \\
\rowcolor[HTML]{EFEFEF} 
\multirow{-2}{*}{\cellcolor[HTML]{EFEFEF}\textbf{Parameter}} &
  \textbf{VIS} &
  \textbf{NIR} &
  \textbf{VIS} &
  \textbf{NIR} \\ \hline
\endfirsthead
%
\endhead
%
\hline
\endfoot
%
\endlastfoot
%
\textbf{ExposureTime (ms)}  & 18264.15 & 498463.3 & 2636.135 & 47487.15 \\
\rowcolor[HTML]{EFEFEF} 
\textbf{Gain}               & 0.0      & 24.1     & 0.0      & 0.0      \\
\textbf{Height (pixels)}    & 1944     & 1944     & 104      & 104      \\
\rowcolor[HTML]{EFEFEF} 
\textbf{Width (pixels)}     & 2592     & 2592     & 104      & 104      \\
\textbf{OffsetX}            & 0        & 0        & 1230     & 1200     \\
\rowcolor[HTML]{EFEFEF} 
\textbf{OffsetY}            & 0        & 0        & 920      & 900      \\
\textbf{Gamma}              & 1.0      & 1.0      & 1.0      & 1.0      \\
\rowcolor[HTML]{EFEFEF} 
\textbf{Hue}                & 0.0      & --       & 0.0      & --       \\
\textbf{BalanceRatio\_Red}  & 1.307617 & --       & 1.289063 & --       \\
\rowcolor[HTML]{EFEFEF} 
\textbf{BalanceRatio\_Blue} & 1.957031 & --       & 1.979004 & --       \\ \hline
\caption{Acquisition Configuration for MTF and FOV Experiments (VIS and NIR)}
\label{tab:tab:fov_mtf}\\
\end{longtable}

Below is a brief description of each parameter used in the configuration:

\begin{itemize}
    \item \textbf{ExposureTime:} Exposure time in milliseconds, determining how long the sensor collects light. Longer exposures increase the captured light but may cause saturation if not properly adjusted.

    \item \textbf{Gain:} Sensor gain factor, amplifying the generated electrical signal. A high gain may increase noise; hence, it is set to 0.0 to avoid unwanted amplification.

    \item \textbf{Gamma:} Gamma correction applied to the image, adjusting the linearity of the light response. A value of 1.0 ensures a linear response.

    \item \textbf{Height (pixels):} Image height in pixels. This parameter defines the vertical resolution and the area of interest.

    \item \textbf{Width (pixels):} Image width in pixels. Together with height, it defines the spatial resolution of the sensor.

    \item \textbf{OffsetX and OffsetY:} Horizontal (OffsetX) and vertical (OffsetY) displacements of the capture area over the sensor. These values help center or adjust the region of interest according to the position of the object or test chart.

    \item \textbf{Hue:} Hue adjustment in the image, used only in color cameras (VIS system). A value of 0.0 means no tonal adjustment is applied.

    \item \textbf{BalanceRatio\_Red and BalanceRatio\_Blue:} White balance ratios for the red and blue channels in color cameras. These coefficients are used to match the responses of each channel and ensure proper white balance. In this study, they were manually adjusted to overlap the peaks of the bright zone in the RGB histograms.
\end{itemize}

These settings are defined to ensure maximum signal without saturation and to avoid clipping in bright and dark areas, guaranteeing that the slanted-edge image is captured under controlled conditions. These parameters are recorded to allow for study replication and for detailed analysis of the optical system response under both low- and high-intensity conditions.

\section{Spectral Characterization of Multispectral Cameras}

Spectral characterization is a fundamental process for color calibration and accurate spectral estimation in multispectral cameras. This process is particularly relevant in applications such as remote sensing, precision agriculture, and environmental analysis, where precision in detecting different wavelengths determines the quality of the obtained data. For this characterization, two main calibration methods using a monochromator were employed: joint calibration of the entire system and separate calibration of its components.

\subsection{Experimental Procedure in the Laboratory}
\label{sec:procedimiento_experimental_laboratorio}

This section details the laboratory procedure used for the spectral response characterization of various optical systems. The methodology includes the selection of the illumination source, validation of its spectrum, beam collimation, dark current correction of the minispectrometer, use of a set of filters and acrylic sheets, selection and combination of said filters, determination of the central wavelength, and measurement of optical power, followed by image capture with the optical system under test.

\subsubsection{Selection and Validation of the Illumination Source}
\label{subsub:fuente_validacion}

A tungsten lamp from ThorLabs, model OSL-2~\cite{OSL2-Manual}, was selected as the main illumination source. This type of lamp emits radiation over a broad range, approximately from 400 nm to 1600 nm, which is suitable for covering both the visible and part of the near-infrared spectrum.

To ensure the spectral distribution of the lamp matched expectations, a minispectrometer from Newport (reference pending) was used to measure its output spectrum. Figure~\ref{fig:lampara_tungsteno_espectro} shows an example of the measured spectral signal, expressed in \textit{counts}, which is the standard output format of such spectrometers. These counts represent the relative intensity recorded by the spectrometer's sensor, but do not constitute an absolute radiometric quantity. Therefore, to obtain a fully calibrated measurement, these counts must be related to the optical power measured by an independent power meter.

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{Figures/C3/tunsteno.png}
    \caption{Example of the measured spectrum of the tungsten lamp (OSL-2) using the minispectrometer. The vertical axis is expressed in counts, which depend on the intrinsic response of the spectrometer.}
    \label{fig:lampara_tungsteno_espectro}
\end{figure}

\subsubsection{Setup and Collimation of the Illumination Beam}
\label{subsub:montaje_colimacion}

The tungsten lamp mentioned includes a fiber optic coupling that allows directing the light toward various optical elements. The wavefront emerging from the fiber optic is \emph{divergent}, so the optical power decreases significantly as the distance between the fiber output and the measurement plane increases. To work under controlled conditions and optimize power utilization, the light beam was \textbf{collimated} by mounting the fiber in a one-inch diameter lens tube.

\begin{enumerate}
    \item \textbf{Selection of the collimating lens:} A plano-convex lens with a focal length of $25$\,mm was selected. Although a longer focal length would reduce divergence, in practice, using lenses with longer focal lengths limits the effective light collection area (especially when the source is not a point source), thus decreasing the total power available in the collimated beam. A 25\,mm lens provides greater light collection, albeit at the cost of slightly more divergence.
    
    \item \textbf{Collimation method:}
    \begin{itemize}
        \item Traditionally, collimation is achieved by measuring the spot size at various distances along the optical axis and adjusting the lens position to find the point where the beam shows a more constant diameter (or minimum divergence) along its propagation. However, this method was not used in this work due to:
        \begin{enumerate}
            \item The lens used is spherical, and the beam coming from the fiber (an extended source) causes noticeable divergence, making it difficult to pinpoint the collimation position solely by observing the spot.
            \item The main goal is to ensure maximum usable optical power at the measurement plane, making it inefficient to characterize beam uniformity based only on spot size.
        \end{enumerate}
        
        \item Instead, an optical power meter is placed at a fixed distance from the collimating lens (see Figure~\ref{fig:montaje_colimacion}).
        \item A 4\,nm bandwidth filter centered at 633\,nm is placed in the optical path to isolate a specific spectral range and reduce dispersive effects.
        \item The distance between the fiber and the lens is varied around the nominal focal length (25\,mm), \emph{searching for the maximum optical power} measured at the detector. This point indicates minimum beam divergence near the measurement plane and maximum power collection.
    \end{itemize}
    
    \item \textbf{Final positioning:} Once the position that maximizes the detected power is found, the positions of the fiber and the lens are mechanically fixed. Additionally, the distance between the lens and the power meter is kept constant for subsequent measurements, ensuring consistent illumination conditions.
\end{enumerate}

\begin{figure}[h!]
    \centering
    \includegraphics[trim=30mm 0mm 40mm 25mm, clip, width=0.9\textwidth]{Figures/C3/colimacion.pdf}
    \caption{Setup for collimating the beam of the tungsten lamp with fiber optics. The adjustment of the distance between the fiber and the plano-convex lens aims to maximize the optical power measured by the detector.}
    \label{fig:montaje_colimacion}
\end{figure}

\subsubsection{Dark Current Correction in the Minispectrometer}
\label{subsub:corriente_oscura_espectrometro}

The minispectrometer used to validate the light source spectrum and measure the transmissions of different filters records a base signal even without illumination, known as \emph{dark current} or \emph{electronic noise}. To improve the accuracy of spectral measurements, the following procedure was applied:

\begin{itemize}
    \item A reference measurement was taken under \textbf{total absence of light} (fiber and input blocked). This signal is denoted by \(\mathbf{D}\) and corresponds to the electronic noise level.
    
    \item For any measured spectrum \(\mathbf{S}\) (e.g., the spectrum of the tungsten lamp or a specific filter), correction is applied by subtracting \(\mathbf{D}\):
    \[
        \mathbf{S}_{\text{corr}} \;=\; \mathbf{S} \;-\; \mathbf{D}.
    \]
\end{itemize}

This attenuates the offset due to readout noise and provides a more reliable reading of the spectral distribution in \emph{counts}.

\subsubsection{Set of Filters and Acrylic Sheets}
\label{subsub:filtros_laminas}

To discretize or modify the spectral distribution of the tungsten lamp, the following elements were used:

\begin{itemize}
    \item \textbf{Nine high-quality optical filters} mountable in one-inch tubes. These filters are numbered from 0 to 6, with two additional filters labeled 532 and 633 (corresponding to their central wavelengths).
    
    \item \textbf{Eight acrylic sheets} of different colors, each 2\,x\,2\,inches, mountable in an optical slide holder.
\end{itemize}

Figure~\ref{fig:laminas_filtros} shows the filters and acrylic sheets with their respective labels. The transmitted spectrum of each element was measured (using the tungsten lamp as the illumination source) with the minispectrometer. These measurements were corrected for dark current as described in Section~\ref{subsub:corriente_oscura_espectrometro}.

\begin{figure}[h!]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{Figures/C3/laminas.pdf}
        \caption{Set of acrylic sheets used. Each is individually labeled based on its apparent color.}
        \label{fig:laminas}
    \end{subfigure}
    \vspace{1em}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=0.8\textwidth]{Figures/C3/filtros.pdf}
        \caption{Set of filters used. Filters are numbered 0 to 6, with two additional filters labeled 532 and 633.}
        \label{fig:filtros}
    \end{subfigure}
    \caption{Acrylic sheets and filters used in the experiment.}
    \label{fig:laminas_filtros}
\end{figure}

\subsubsection{Measurement of Transmission Spectra}
\label{subsub:medicion_transmision}

The transmission spectra of each filter and acrylic sheet are measured to determine their effective spectral transmission. Figure~\ref{fig:montaje_spec} shows the optical setup used to measure the transmission spectrum.

\begin{figure}[h!]
    \centering
    \includegraphics[trim=30mm 0mm 40mm 25mm, clip, width=0.9\textwidth]{Figures/C3/montaje_spec.pdf}
    \caption{Setup for measuring the transmission spectrum of filters and acrylic sheets.}
    \label{fig:montaje_spec}
\end{figure}

\begin{itemize}
    \item For the \textbf{illumination}, the base spectrum \(\mathbf{I}\) is obtained (dark-current corrected).
    \item For each \textbf{filter} or \textbf{sheet}, the transmitted spectrum \(\mathbf{T}_j\) is measured, also corrected for dark current.
\end{itemize}

The recorded spectra are shown in Figure~\ref{fig:espectros_combinados}. Then, the dimensionless relative spectral response for each element is calculated by dividing \(\mathbf{T}_j\) by \(\mathbf{I}\). The justification lies in the fact that, in linear systems, the transmission is modeled as a multiplication of the source spectrum by the spectral transfer function of the element (filter or sheet):

\[
    \mathbf{T}_j \;=\; \mathbf{I} \;\times\; \beta_j(\lambda),
\]
\[
    \frac{\mathbf{T}_j}{\mathbf{I}} \;=\; \beta_j(\lambda).
\]

Thus, the curve \(\beta_j(\lambda)\) represents the \textbf{effective spectral transmittance} of the filter or sheet (see Figure~\ref{ig:filtros_laminas_espectros_relativos}).

\begin{figure}[h!]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[trim=0mm 0mm 0mm 25mm, clip, width=0.9\textwidth]{Figures/C3/filtros_spec.png}
        \caption{Filters.}
        \label{fig:filtros_espectros}
    \end{subfigure}
    \vspace{1em}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[trim=0mm 0mm 0mm 25mm, clip, width=0.9\textwidth]{Figures/C3/laminas_spec.png}
        \caption{Acrylic plates.}
        \label{fig:laminas_espectros}
    \end{subfigure}
    \caption{Measured spectra (in counts) of tungsten light transmitted through various filters (A) and acrylic plates (B). The vertical axis shows the relative intensity recorded by the minispectrometer in counts.}
    \label{fig:espectros_combinados}
\end{figure}

\begin{figure}[h!]
    \centering
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[trim=0mm 0mm 0mm 25mm, clip, width=0.9\textwidth]{Figures/C3/filtros_respuestaspec.png}
        \caption{Filters.}
        \label{fig:filtros_espectros}
    \end{subfigure}
    \vspace{1em}
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[trim=0mm 0mm 0mm 25mm, clip, width=0.9\textwidth]{Figures/C3/laminas_respuestaspec.png}
        \caption{Acrylic plates.}
        \label{fig:laminas_espectros}
    \end{subfigure}
    \caption{Normalized dimensionless spectral response (transmittance) obtained by dividing each filtered spectrum by the tungsten lamp spectrum.}
    \label{ig:filtros_laminas_espectros_relativos}
\end{figure}

\subsubsection{Generación y selección de combinaciones de filtros}
\label{subsub:combinaciones_filtros}

\subsubsection{Generation and Selection of Filter Combinations}
\label{subsub:combinaciones_filtros}

Given that the filters have relatively wide bandwidths (many exceeding 100 nm), this work evaluates the possibility of combining up to three filters to obtain more selective transmission curves. A \texttt{Python} script is developed that:

\begin{enumerate}
    \item Lists all possible combinations of:
    \begin{itemize}
        \item Individual filters and/or acrylic sheets,
        \item Pairs of filters/sheets,
        \item Triplets of filters/sheets.
    \end{itemize}
    \item For each combination, calculates the \emph{composite transmission curve} \(\beta_{\text{comp}}(\lambda)\), which is the \textbf{product} of the individual transmissions as a function of wavelength.
    \item Generates a total of 987 combinations (including single, double, and triple combinations).
\end{enumerate}

\paragraph{Ideal Transmission Curves.}
To guide the selection process, 10 target curves are defined, modeled as Gaussian functions with a standard deviation of 3\,nm:

\begin{itemize}
    \item Seven curves centered in the visible spectrum: 400, 450, 500, 550, 600, 650, and 700\,nm.
    \item Three curves for the near-infrared (NIR): 825, 850, and 875\,nm.
\end{itemize}

Each \(\beta_{\text{ideal}}(\lambda)\) adopts the form:
\[
\beta_{\text{ideal}}(\lambda) \;=\; \exp\!\Big[-\tfrac{(\lambda - \lambda_0)^2}{2 \,\sigma^2}\Big],
\]
where \(\lambda_0\) is the central wavelength and \(\sigma=3\) nm.  
Figure~\ref{fig:curvas_ideales} illustrates the ideal profiles used.

\begin{figure}[h!]
    \centering
    \includegraphics[trim=0mm 0mm 0mm 25mm, clip, width=1\textwidth]{Figures/C3/ideal_spec.png}
    \caption{Ideal transmission curves for selecting filter combinations. This example shows 10 Gaussians centered at 400, 450, 500, 550, 600, 650, 700, 825, 850, and 875 nm, respectively.}
    \label{fig:curvas_ideales}
\end{figure}

\paragraph{Selection Metric.}
To determine which filter combination best matches the defined ideal curves, the Pearson correlation coefficient is used. Given an ideal curve \(\beta_{\text{ideal}}(\lambda)\) and a composite curve \(\beta_{\text{comp}}(\lambda)\), both discretized in \(N\) spectral points, the Pearson correlation coefficient \(r\) is defined as:

\begin{equation}
r(\beta_{\text{ideal}}, \beta_{\text{comp}}) =
\frac{
    \displaystyle \sum_{i=1}^{N} 
    \left[\beta_{\text{ideal}}(\lambda_i) - \bar{\beta}_{\text{ideal}}\right]
    \left[\beta_{\text{comp}}(\lambda_i) - \bar{\beta}_{\text{comp}}\right]
}{
    \sqrt{
        \left(
        \displaystyle \sum_{i=1}^{N} 
        \left[\beta_{\text{ideal}}(\lambda_i) - \bar{\beta}_{\text{ideal}}\right]^2
        \right)
        \left(
        \displaystyle \sum_{i=1}^{N} 
        \left[\beta_{\text{comp}}(\lambda_i) - \bar{\beta}_{\text{comp}}\right]^2
        \right)
    }
}
\end{equation}

where:
\begin{itemize}
    \item \(\beta_{\text{ideal}}(\lambda_i)\) is the ideal transmission at wavelength \(\lambda_i\),
    \item \(\beta_{\text{comp}}(\lambda_i)\) is the composite transmission of the filter combination at \(\lambda_i\),
    \item \(\bar{\beta}_{\text{ideal}}\) and \(\bar{\beta}_{\text{comp}}\) are the mean values of each curve across the evaluated range.
\end{itemize}

The Pearson coefficient ranges from \([-1, 1]\). A value close to 1 indicates high similarity in shape and relative distribution; values near 0 or negative indicate low similarity. Therefore, the combination with the highest \(r\) is selected as the “optimal” match for a given target curve.

\medskip

\noindent
\textbf{Selection Procedure:}
\begin{enumerate}
    \item For each ideal curve \(\beta_{\text{ideal}}(\lambda)\), all composite curves \(\beta_{\text{comp}}(\lambda)\) are evaluated.
    \item \(r(\beta_{\text{ideal}}, \beta_{\text{comp}})\) is computed over the same wavelength range.
    \item The combination that maximizes \(r\) is selected.
\end{enumerate}

This method allows identifying the filter combination that best approximates a desired spectral shape. For each central wavelength (e.g., 400, 450, 500, …, 700, 825, 850, and 875\,nm), an “optimal” combination is thus obtained. Figure~\ref{fig:best_corr_combinations} shows an example of the best-matching filter combinations overlaid on their corresponding ideal curves.

\begin{figure}[htbp]
    \centering
    \includegraphics[trim=0mm 0mm 0mm 25mm, clip, width=1\textwidth]{Figures/C3/best_matches.png}
    \caption{Filter combinations (solid lines) with the highest correlation to their corresponding ideal curves (dashed lines). The shape and peak position of the selected combinations match the target profiles.}
    \label{fig:best_corr_combinations}
\end{figure}

\medskip

\noindent
Additionally, some combinations are selected experimentally, since the correlation-based method does not consider absolute transmittance. It is possible that the combination with the highest correlation \(r\) has very low transmittance, limiting its practical utility. Also, individual filters such as those centered at 532 and 633\,nm show good spectral performance. By combining the maximum correlation criterion with experimental validation, the final set of filters used for spectral characterization is selected.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{Figures/C3/filt_select.png}
    \caption{Final filter selection used for spectral characterization of the optical systems. Includes both experimentally selected configurations and individual filters (532 and 633 nm) showing good correlation and transmittance.}
    \label{fig:selected_filters}
\end{figure}

\subsubsection{Determination of Central Wavelength, Bandwidth, and Optical Power of Selected Combinations}
\label{subsub:longitud_onda_central_potencia}

After defining the optimal combinations, the actual transmission spectra are measured using the minispectrometer to verify the effective central wavelength, resulting bandwidth, and transmitted optical power. This is essential to:

\begin{enumerate}
    \item Properly configure the optical power meter (which requires the central wavelength of the incoming radiation).
    \item Verify that the actual transmission curves are consistent with the numerically determined ones.
\end{enumerate}

The optical power transmitted by each selected combination is then measured using a power meter. To maintain consistency across measurements:

\begin{itemize}
    \item The tungsten lamp operates at its \textbf{maximum irradiance capacity}.
    \item For each combination, the power is measured at the previously determined central wavelength \(\lambda_0\).
\end{itemize}

The lowest power value among all combinations is used as the reference. This ensures that subsequent optical system measurements are performed under the same irradiance conditions, using neutral density filters to reduce irradiance in cases where power exceeds this reference.

\medskip

The bandwidth of the measured spectra for each selected filter is also calculated. Each spectrum is first normalized to have a maximum value of 1. The bandwidth is defined as the spectral interval where the signal reaches at least 50\% of its maximum value (i.e., the Full Width at Half Maximum, FWHM). For filters with multiple peaks, the main peak of interest is selected, usually corresponding to the expected region (e.g., NIR).

A Python script is developed that:

\begin{enumerate}
    \item Identifies the maximum peak of each normalized spectrum.
    \item Determines the wavelengths \(\lambda_{\text{left}}\) and \(\lambda_{\text{right}}\) where the spectral response falls to 50\% of the maximum.
    \item Calculates the bandwidth as:
    \[
    \text{FWHM} = \lambda_{\text{right}} - \lambda_{\text{left}}.
    \]
\end{enumerate}

Figure~\ref{fig:bandwidth_central} shows the central wavelength and FWHM of the selected filters, obtained through the described procedure. These parameters are key to assessing the system’s ability to discriminate spectral bands and for configuring the power meter accurately.

\begin{figure}[htbp]
    \centering
    \includegraphics[trim=0mm 0mm 50mm 25mm, clip, width=1\textwidth]{Figures/C3/ancho de banda.png}
    \caption{Example of a normalized spectrum of a selected filter. The central wavelength and bandwidth (FWHM) are indicated, defined as the spectral range where the signal reaches 50\% of its maximum value.}
    \label{fig:bandwidth_central}
\end{figure}

\subsubsection{Image Capture with the Optical System Under Test}
\label{subsub:captura_sistemas_opticos}

Once the filter combinations are defined and the optical power is adjusted, the characterization of the target optical systems (e.g., an RGB system and/or a monochannel NIR system) is performed. The procedure is as follows:

\begin{enumerate}
    \item \textbf{Camera or sensor configuration:}
    \begin{itemize}
        \item \emph{Gain:} Set to $1$ for all measurements to avoid scaling differences between captures.
        \item \emph{Gamma:} Set to $1$ (linear) to suppress any internal nonlinearity curves.
        \item \emph{White balance:} In RGB cameras, the red and blue coefficients are set to $1$, and the green channel is also set to $1$ (if allowed by the firmware). This ensures that the camera does not apply color corrections.
    \end{itemize}
    
    \item \textbf{Use of neutral density filters (optional):} If the power exceeds the reference level, a neutral density filter is inserted into the lens tube after collimation. This ensures the same final power for all combinations.
    
    \item \textbf{Exposure time adjustment:} The exposure time is set to avoid image saturation. This value is recorded, since the system's response is \textbf{linearly proportional} to the integration time (see Equation~\ref{eq:modelo_lineal}).
    
    \item \textbf{Data capture:}
    \begin{itemize}
        \item For each selected filter combination, $50$ consecutive images of the optical system are acquired and saved in an uncompressed or minimally processed format. In this case, the format used is .npy.
        \item Additionally, $50$ dark current images are taken by completely covering the objective.
    \end{itemize}
    
    \item \textbf{Noise correction and averaging:}
    \begin{itemize}
        \item The average of the 50 dark current images is calculated, resulting in an image \(\mathbf{D}_{\text{prom}}\) that represents the system’s electronic offset.
        \item Each of the 50 illuminated captures is corrected by subtracting \(\mathbf{D}_{\text{prom}}\), thereby eliminating the dark current contribution.
        \item The 50 corrected images are then averaged, generating a single image \(\mathbf{I}_{\text{filt}}\) for each filter combination.
    \end{itemize}
    
    \item \textbf{Spectral response calculation:}
    \begin{itemize}
        \item For each averaged image (\(\mathbf{I}_{\text{filt}}\)), a \emph{response} metric is defined as the sum of all pixel values within the region of interest. In the case of an RGB camera, this sum can be calculated per channel (R, G, or B), or by converting the image to grayscale.
        \item In a monochromatic or NIR camera, the single available channel is used.
        \item The resulting value represents the system’s total response to the corresponding filter combination, associated with the calculated \(\lambda_0\).
    \end{itemize}
\end{enumerate}

\noindent
This process is repeated for each selected filter/sheet combination, generating a discrete spectral response map of the optical system, which relates the central wavelength to the response (as grayscale level sum or per channel).


\section{Main contributions}
%---------------------------------------------------------------
     %===============================================================
     \subsection{Resultados de la caracterización del campo de visión (FOV)}
     \label{sec:fov_resultados}
     %===============================================================
     
     Para validar el campo de visión de los sistemas ópticos seleccionados (Sistema 7 VIS y Sistema 6 NIR), se realizaron mediciones de FOV horizontal (H) y vertical (V) a tres distancias de trabajo (\(\mathrm{WD}\)) empleando la carta de prueba ISO 12233. A continuación se presentan los resultados obtenidos.\\
     
     La Figura \ref{fig:fov_montage} muestra las 12 capturas originales (3 filas × 4 columnas) utilizadas para determinar experimentalmente el FOV. Cada fila corresponde a una distancia de trabajo distinta; las dos primeras columnas son las mediciones H y V de VIS (Sistema 7) y las dos últimas, las de NIR (Sistema 6).
     
     \begin{figure}[H]
       \centering
       \setlength{\tabcolsep}{2pt}
       \renewcommand{\arraystretch}{0}
       \begin{tabular}{cccc}
         \multicolumn{2}{c}{\small NIR – Sistema 6} &
         \multicolumn{2}{c}{\small VIS – Sistema 7} \\
         H & V & H & V \\ 
 
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/NIR/H/7_1.png} &
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/NIR/V/8_7.png} &
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/VIS/H/9_2.png} &
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/VIS/V/10_7.png} \\
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/NIR/H/33_1.png} &
         \includegraphics[trim= 6cm 6cm 6cm 6cm, clip, width=.22\linewidth]{Figures/C4/FOV/NIR/V/65.png} & % TOCLIP
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/VIS/H/37_8.png} &
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/VIS/V/30_3.png} \\
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/NIR/H/63.png} &
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/NIR/V/65.png} &
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/VIS/H/69_4.png} &
         \includegraphics[width=.22\linewidth]{Figures/C4/FOV/VIS/V/70.png} \\
       \end{tabular}
       \caption{Imágenes originales para la medición del FOV horizontal (H)
                y vertical (V) en tres distancias de trabajo.}
       \label{fig:fov_montage}
     \end{figure}
     
     Las mediciones, convertidas a metros, se resumen en la Tabla \ref{tab:fov_raw_wd}, donde cada FOV se acompaña de una incertidumbre instrumental \(\sigma=1\) mm.
     
     \begin{table}[H]
       \centering
       \caption{WD y FOV medidos para cada sistema óptico y orientación}
       \label{tab:fov_raw_wd}
       \small
       \setlength{\tabcolsep}{4pt} % Espaciado más compacto entre columnas
       \renewcommand{\arraystretch}{1.2} % Espaciado entre filas
       \begin{tabularx}{\textwidth}{|c|>{\centering\arraybackslash}X
                                         >{\centering\arraybackslash}X
                                         >{\centering\arraybackslash}X
                                         >{\centering\arraybackslash}X|
                                         >{\centering\arraybackslash}X
                                         >{\centering\arraybackslash}X
                                         >{\centering\arraybackslash}X
                                         >{\centering\arraybackslash}X|}
         \hline
         \rowcolor[HTML]{EFEFEF}
         & \multicolumn{4}{c|}{\textbf{NIR (Sis.~6)}} 
         & \multicolumn{4}{c|}{\textbf{VIS (Sis.~7)}} \\ \cline{2-9}
         \rowcolor[HTML]{EFEFEF}
         \textbf{Prueba} 
           & WD$_H$ [m] & FOV$_H$ [m] & WD$_V$ [m] & FOV$_V$ [m] 
           & WD$_H$ [m] & FOV$_H$ [m] & WD$_V$ [m] & FOV$_V$ [m] \\ 
         \hline
         1 & 0.071 & 0.0350 & 0.087 & 0.0350 & 0.092 & 0.0350 & 0.107 & 0.0350 \\
         2 & 0.331 & 0.231  & 0.350 & 0.180  & 0.379 & 0.239  & 0.303 & 0.138  \\
         3 & 0.650 & 0.468  & 0.650 & 0.349  & 0.694 & 0.458  & 0.700 & 0.342  \\ 
         \hline
       \end{tabularx}
     \end{table}
 
     
     
     Aplicando regresión lineal ponderada (Deming) con pesos \(w=1/\sigma\), los ajustes óptimos fueron:
     
     \[
     \begin{aligned}
     \text{VIS:}\;&\mathrm{FOV_H}=(0.7025\pm0.0045)\,\mathrm{WD}-(0.0288\pm0.0021),\\
     \text{VIS:}\;&\mathrm{FOV_V}=(0.5171\pm0.0029)\,\mathrm{WD}-(0.0197\pm0.0013),\\
     \text{NIR:}\;&\mathrm{FOV_H}=(0.7477\pm0.0031)\,\mathrm{WD}-(0.0175\pm0.0013),\\
     \text{NIR:}\;&\mathrm{FOV_V}=(0.5579\pm0.0034)\,\mathrm{WD}-(0.0141\pm0.0015).
     \end{aligned}
     \]
     
     La Figura \ref{fig:fov_reg_combined} ilustra los ajustes con sus bandas de confianza \(1\sigma\).
     
     \begin{figure}[H]
     \centering
       \includegraphics[width=1\linewidth]{Figures/C4/FOV.png}
       \caption{Ajuste lineal ponderado de FOV vs.\ WD para los cuatro casos: VIS–H, VIS–V, NIR–H y NIR–V .}
       \label{fig:fov_reg_combined}
     \end{figure}
     
 
     
     La Tabla \ref{tab:fov_pred_vs_theory_HV} compara el FOV horizontal predicho
     por los ajustes empíricos con los valores teóricos calculados en
     la Sección \ref{sec:cad_sim} para alturas de 50 m, 1000 m y 5000 m.
     
 
     
     \begin{table}[H]
      \label{tab:fov_pred_vs_theory_HV}
       \centering
       \caption{Comparativa empírico vs. teórico para FOV horizontal (H) y vertical (V).}
       \small
       \begin{tabular*}{\columnwidth}{@{\extracolsep{\fill}}|
           c|
           rrrr|
           rrrr|
         }
         \toprule
          & \multicolumn{4}{c|}{\shortstack{\textbf{VIS}\\(Sis.~7)}} 
            & \multicolumn{4}{c|}{\shortstack{\textbf{NIR}\\(Sis.~6)}} \\
         \midrule
         \textbf{Altura}
           & \shortstack{Pred H\\(m)} 
           & \shortstack{Teo H\\(m)} 
           & \shortstack{Pred V\\(m)} 
           & \shortstack{Teo V\\(m)} 
           & \shortstack{Pred H\\(m)} 
           & \shortstack{Teo H\\(m)} 
           & \shortstack{Pred V\\(m)} 
           & \shortstack{Teo V\\(m)} \\
         \midrule
         50\,m   
           &  35.10  &  33.54   &  25.84  &  25.16 
           &  37.37  &  35.64   &  27.88  &  26.73  \\
         1000\,m 
           & 702.50  & 670.87   & 517.08  & 503.15  
           & 747.70  & 712.8    & 557.90  & 534.6   \\
         5000\,m 
           & 3512.00 & 3354.35  & 2585.48 & 2515.76 
           & 3737.00 & 3564     & 2788.89 & 2673    \\
         \bottomrule
       \end{tabular*}
     \end{table}
 
     
 
     Con estos resultados, se puedes definir las discrepancias como:
     \[
       \Delta_{\mathrm{abs}} = FOV_{\mathrm{pred}} - FOV_{\mathrm{teo}},
       \qquad
       \Delta_{\mathrm{rel}} = \frac{\Delta_{\mathrm{abs}}}{FOV_{\mathrm{teo}}}\times100\%.
     \]
     A continuación se presentan los resultados para cada altura y sistema:
     
     \begin{align*}
     50\,\mathrm{m}:&\quad
     \Delta_{\mathrm{abs}}^{\mathrm{VIS}} = 35.10 - 33.54 = 1.56\,\mathrm{m}, 
     \quad
     \Delta_{\mathrm{rel}}^{\mathrm{VIS}} = \frac{1.56}{33.54}\times100\%\approx4.65\%,\\
     &\quad
     \Delta_{\mathrm{abs}}^{\mathrm{NIR}} = 37.37 - 35.64 = 1.73\,\mathrm{m}, 
     \quad
     \Delta_{\mathrm{rel}}^{\mathrm{NIR}} = \frac{1.73}{35.64}\times100\%\approx4.85\%.\\[6pt]
     1000\,\mathrm{m}:&\quad
     \Delta_{\mathrm{abs}}^{\mathrm{VIS}} = 702.5 - 670.9 = 31.6\,\mathrm{m}, 
     \quad
     \Delta_{\mathrm{rel}}^{\mathrm{VIS}} = \frac{31.6}{670.9}\times100\%\approx4.71\%,\\
     &\quad
     \Delta_{\mathrm{abs}}^{\mathrm{NIR}} = 747.7 - 712.8 = 34.9\,\mathrm{m}, 
     \quad
     \Delta_{\mathrm{rel}}^{\mathrm{NIR}} = \frac{34.9}{712.8}\times100\%\approx4.90\%.\\[6pt]
     5000\,\mathrm{m}:&\quad
     \Delta_{\mathrm{abs}}^{\mathrm{VIS}} = 3512 - 3354 = 158\,\mathrm{m}, 
     \quad
     \Delta_{\mathrm{rel}}^{\mathrm{VIS}} = \frac{158}{3354}\times100\%\approx4.71\%,\\
     &\quad
     \Delta_{\mathrm{abs}}^{\mathrm{NIR}} = 3737 - 3564 = 173\,\mathrm{m}, 
     \quad
     \Delta_{\mathrm{rel}}^{\mathrm{NIR}} = \frac{173}{3564}\times100\%\approx4.86\%.
     \end{align*}
 
     
     Los resultados confirman que, en ambos sistemas, la discrepancia relativa se mantiene entre un 4.6–4.9 \% independientemente de la altura de operación. Este sesgo prácticamente constante refuerza la hipótesis de un error geométrico sistemático (distorsión radial y paralaje en la medida de WD) que debe corregirse antes de la generación de ortomosaicos. 
     
     
     \subsection{Caracterización angular: AFOV vs.\ WD}
     Las figuras \ref{fig:afov} presentan dos curvas para cada sistema: horizontal y vertical. En el caso VIS, el AFOV crece hacia el valor teórico sin sobrepasarlo; en NIR, el experimento supera ligeramente el teórico a medida que WD aumenta, sugiriendo un enfoque ligeramente desajustado. \\
 
     1\begin{figure}[H]
       \centering
       \begin{subfigure}[b]{.9\linewidth}
         \includegraphics[width=\linewidth]{Figures/C4/afov_nir.png}
         \caption{NIR – Sistema 6}
       \end{subfigure}
       \hfill
       \begin{subfigure}[b]{0.9\linewidth}
         \includegraphics[width=\linewidth]{Figures/C4/afov_vis.png}
         \caption{VIS – Sistema 7}
       \end{subfigure}
       \caption{AFOV experimental vs.\ WD (flecha punteada: valor teórico).}
       \label{fig:afov}
     \end{figure}
     
     Para cuantificar la convergencia, en la Tabla~\ref{tab:afov_exp} se resumen los valores experimentales de AFOV en los tres WD medidos. A la mayor distancia, la discrepancia horizontal con el valor teórico ($37.1^\circ$ para VIS y $39.3^\circ$ para NIR) es:
     \[
     \begin{aligned}
     \Delta_{\rm abs}^{\rm VIS\text{-}H} &=36.52^\circ - 37.10^\circ = -0.58^\circ\quad(\Delta_{\rm rel}\approx1.6\%),\\
     \Delta_{\rm abs}^{\rm NIR\text{-}H} &=39.60^\circ - 39.30^\circ = +0.30^\circ\quad(\Delta_{\rm rel}\approx0.8\%).
     \end{aligned}
     \]
     Verticalmente, comparando con el valor teórico de $28.24^\circ$, para WD máximo:
     \[
     \begin{aligned}
     \Delta_{\rm abs}^{\rm VIS\text{-}V} &=27.46^\circ - 28.24^\circ = -0.78^\circ\quad(\Delta_{\rm rel}\approx2.8\%),\\
     \Delta_{\rm abs}^{\rm NIR\text{-}V} &=30.05^\circ - 28.24^\circ = +1.81^\circ\quad(\Delta_{\rm rel}\approx6.4\%).
     \end{aligned}
     \]
     
     \begin{table}[H]
       \centering
       \caption{AFOV experimental para WD de 0.07–0.09 m, 0.30–0.38 m y 0.65–0.70 m.}
       \label{tab:afov_exp}
       \begin{tabular}{lccc}
         \toprule
         Sistema & WD [m] & AFOV$_H$ [°] & AFOV$_V$ [°] \\
         \midrule
         \textbf{VIS (Sistema 7)} 
           & 0.09 & 21.54 & 18.58 \\
           & 0.38 & 35.00 & 25.66 \\
           & 0.69 & 36.52 & 27.46 \\
         \midrule
         \textbf{NIR (Sistema 6)} 
           & 0.07 & 27.69 & 22.75 \\
           & 0.33 & 38.47 & 28.84 \\
           & 0.65 & 39.60 & 30.05 \\
         \bottomrule
       \end{tabular}
     \end{table}
    
    %---------------------------------------------------------------
    \subsection{Magnificación primaria (PMAG) de los sistemas 6 (NIR) y 7 (VIS)}
    \label{sec:pmag}
    %---------------------------------------------------------------

    Por otro lado, a partir de la ecuación \ref{eq:pmag}, se obtuvó la magnificación primara para ambos sistemas NIR y VIS para cada valor de altitud, como se muestra en la Tabla \ref{tab:pmag_sys67}.

    \begin{table}[h]
      \centering
      \caption{Magnificación primaria (\textit{PMAG}) de los sistemas VIS (Sis.~7) y NIR (Sis.~6) a distintas alturas.}
      \label{tab:pmag}
      \begin{tabular}{|c|c|c|}
          \hline
          \rowcolor[HTML]{EFEFEF}
          \textbf{Altura [m]} & \textbf{PMAG VIS (Sis.~7)} & \textbf{PMAG NIR (Sis.~6)} \\
          \hline
          50   & $1.62\times10^{-4}$ & $1.53\times10^{-4}$ \\
          1000 & $8.12\times10^{-6}$ & $7.63\times10^{-6}$ \\
          5000 & $1.62\times10^{-6}$ & $1.53\times10^{-6}$ \\
          \hline
      \end{tabular}
    \end{table}
  
    Para el rango operacional propuesto (50–5000 m) las diferencias
    entre ambos sistemas son $<\,6\,\%$, consecuencia de que comparten el mismo
    tamaño de sensor y distancias focales muy próximas
    (8.0 mm – NIR, 8.5 mm – VIS).  

     \subsection{Modulation Transfer Function (MTF) Measurements}
      \label{sec:mtf_results}
      Aunque el montaje experimental para la caracterización de la MTF se describió en la metodología (véase la Figura~\ref{fig:srf_motaje}), durante las primeras pruebas se constató que el contraste entre las zonas claras y oscuras resultaba insuficiente para aplicar con fiabilidad el método ISO 12233. Según este estándar, el test chart debe presentar un contraste mínimo de 4:1 y una distribución de irradiancia lo más uniforme posible en ambas regiones, de modo que el histograma de intensidad exhiba dos picos nítidos (uno correspondiente a las zonas claras y otro a las zonas oscuras). Sin embargo, al analizar la carta de prueba impresa en papel mate —una reprografía de bajo costo— se observó una continuidad de valores intermedios y múltiples picos espurios que comprometían la extracción precisa de la Edge Spread Function (ESF). Esta carta de ruebas puede ser adquirida por proveedores de isntrumentos ópticos, pero su costo es elevado.\\

      \begin{figure}[h]
          \centering
          \includegraphics[width=0.7\linewidth]{Figures/C4/MTF_chart_hist.png}
          \caption{Histograma de la carta de prueba ISO 12233 impresa en papel mate. Se aprecian tres picos en la región oscura y dos picos muy anchos en la región clara, reflejo de una alta desviación estándar y de un contraste inferior al requerido por la norma.}
          \label{fig:histogram_iso12233}
      \end{figure}
      
      El origen de esta dispersión radica en dos factores principales. Primero, la calidad de impresión (impreso en una impresora de un proveedor local no especializado en cartas para pruebas ópticas de laboratorio) del test chart no garantizaba bordes suficientemente definidos ni un nvel de negros que proporsionaran el suficiente contraste ni precisión en la impresión de lineas. Segundo, el esquema de iluminación no siguió estrictamente la recomendación de emplear dos fuentes homogéneas (véase la Figura~\ref{fig:srf_motaje}), lo cual impidió alcanzar una irradiancia uniforme sobre la carta y acentuó las zonas de sombra y reflejo. Ante ello, se optó por un patrón de prueba empírico, el cual consistía en una hoja de papel inlcinada y un fondo oscuro, y por limitar la región de interés a un área de 104 $\times$ 104 píxeles, de forma que la iluminación pudiera controlarse de manera más rigurosa.\\
      
      La imagen finalmente utilizada para la determinación de la MTF —mostrada en la Figura~\ref{fig:enfoque}— fue corregida previamente, en primer lugar, de la corriente oscura según se describe en la Sección~\ref{subsub:corriente_oscura_espectrometro}, y, en segundo lugar, de los errores aleatorios mediante el promediado de múltiples capturas (tal como se detalló en la metodología de MTF). Sobre estas imágenes corregidas se generaron histogramas de intensidad para cada sistema, a fin de verificar que ahora sí se obtenía una distribución bimodal aceptable.
      
      \begin{figure}[h]
          \centering
          \begin{subfigure}[b]{\linewidth}
              \centering
              \includegraphics[width=\linewidth]{Figures/C4/hist_vis_MTF.png}
              \caption{Sistema VIS: histogramas de los canales R, G y B después de correcciones.}
              \label{fig:histogram_vis}
          \end{subfigure}
          \hfill
          \begin{subfigure}[b]{\linewidth}
              \centering
              \includegraphics[width=\linewidth]{Figures/C4/hist_nir_MTF.png}
              \caption{Sistema NIR: histograma de su único canal tras correcciones.}
              \label{fig:histogram_nir}
          \end{subfigure}
          \caption{Distribución de valores de intensidad en imágenes corregidas (corriente oscura y ruido aleatorio) para los sistemas VIS y NIR, empleadas en la extracción de la MTF.}
          \label{fig:histogram_vis_nir}
      \end{figure}
      
      Con estas condiciones mejoradas se pudo proceder a extraer la ESF y, posteriormente, la Line Spread Function (LSF) y su transformada de Fourier para obtener las curvas de MTF de ambos sistemas. Este rigor en la corrección y control de iluminación garantiza que las mediciones resultantes reflejen fielmente la capacidad de resolución de los ópticos evaluados.      % Breve recordatorio de cómo se obtuvieron las curvas MTF (ISO 12233, número de imágenes, condiciones de enfoque, aperturas, exposición, etc.) 
      
    %---------------------------------------------------------------
    \subsubsection{MTF Curves for VIS and NIR Systems}
    \label{subsub:mtf_curves}
    %---------------------------------------------------------------
    Las curvas MTF se obtuvieron con el \textit{plugin} \texttt{SE\_MTF} de \textit{ImageJ} siguiendo el procedimiento descrito en la sección~\ref{sec:mtf_char}.  
    Para el sistema VIS (Sistema 7) se procesaron independientemente los tres canales \(R\), \(G\) y \(B\) y, adicionalmente, la imagen promedio (\textit{Mono}).  
    Para el sistema NIR (Sistema 6) únicamente se dispone de un canal monocromático.

    \begin{figure}[H]
        \centering
        %-----------------------------------------------------------
        \begin{subfigure}[b]{0.95\linewidth}
            \centering
            \includegraphics[width=\linewidth]{Figures/C4/mtf_vis.png}
            \caption{Sistema VIS: MTF de los canales \(R\), \(G\), \(B\) y promedio (\textit{Mono}).}
            \label{fig:mtf_vis}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.95\linewidth}
            \centering
            \includegraphics[width=\linewidth]{Figures/C4/mtf_nir.png}
            \caption{Sistema NIR: MTF del canal monocromático.}
            \label{fig:mtf_nir}
        \end{subfigure}
        %-----------------------------------------------------------
        \caption{Curvas MTF obtenidas con \textit{ImageJ}.  
                La configuración del \textit{plugin} se muestra en la Fig.~\ref{fig:plugin_config1}. Esta medida fue tomada con una distancia de trabajo de 925 mm.}
        \label{fig:mtf_curves}
    \end{figure}

    Los puntos donde la modulación cae al \(30\,\%\) proporcionan la frecuencia de corte \(f_{\text{im}}\).  
    La Tabla~\ref{tab:cutoff_meas} resume estos valores y los compara con las especificaciones teóricas (Tabla~\ref{tab:sys_tables}).

    \begin{table}[H]
        \centering
        \caption{Frecuencia de corte a \(30\,\%\) de contraste: mediciones frente a especificación.}
        \label{tab:cutoff_meas}
        \begin{tabular}{|c|c|c|c|}
            \hline
            \rowcolor[HTML]{EFEFEF}
            \textbf{Sistema / Canal} &
            \(\mathbf{f_{\text{im,\,meas}}}\) [lp mm\(^{-1}\)] &
            \(\mathbf{f_{\text{im,\,theo}}}\) [lp mm\(^{-1}\)] &
            \(\mathbf{\Delta\,[\%]}\) \\ \hline
            VIS – \(R\)     &  57.72 & 85  & \(-32.1\) \\ \hline
            VIS – \(G\)     &  79.36 & 85  &  \(-6.6\) \\ \hline
            VIS – \(B\)     &  72.15 & 85  & \(-15.1\) \\ \hline
            VIS – Mono      &  72.15 & 85  & \(-15.1\) \\ \hline
            NIR – Mono      &  79.36 & 120 & \(-33.9\) \\ \hline
        \end{tabular}
    \end{table}

    %---------------------------------------------------------------
    \subsubsection{Cut-off Frequency and Ground Resolution Calculation}
    \label{subsub:grd_calc}
    %---------------------------------------------------------------
    La resolución en tierra (\(\Delta_{\text{ground}}\)) se obtuvo aplicando los pasos 1–3 de la sección~\ref{subsub:grd_from_mtf}.  
    Para cada canal se parte del \(f_{\text{im,\,meas}}\) de la Tabla~\ref{tab:cutoff_meas}; se calcula la frecuencia en el objeto
    $f_{\text{obj}}$ y, posteriormente,
    $\Delta_{\text{ground}}$.  
    Los parámetros geométricos (PMAG y FOV) provienen de la Tabla~\ref{tab:grd_fov_clean}; las distancias focales son
    \(f_{\text{VIS}} = 8.5\,\mathrm{mm}\) y \(f_{\text{NIR}} = 8.0\,\mathrm{mm}\).

    %--------------------------------------------------------------
    \begin{table}[H]
        \centering
        \caption{Resolución en tierra \(\Delta_{\text{ground}}\) – Sistema VIS (Sis.~7)}
        \label{tab:grd_vis_corrected}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \rowcolor[HTML]{EFEFEF}
            \textbf{Canal} &
            \multicolumn{3}{c|}{\(\mathbf{\Delta_{\text{ground}}\,[\text{cm}]}\)} &
            \(\mathbf{\Delta_{\text{ground}}\,[\text{m}]}\) \\ \cline{2-4}
            \rowcolor[HTML]{EFEFEF}
            & 50 m & 1000 m & 5000 m & 5000 m \\ \hline
            \(R\)   & 5.35 & 106.68 & 534.72 & 5.35 \\ \hline
            \(G\)   & 3.89 &  77.59 & 388.91 & 3.89 \\ \hline
            \(B\)   & 4.28 &  85.34 & 427.78 & 4.28 \\ \hline
            Mono    & 4.28 &  85.34 & 427.78 & 4.28 \\ \hline
        \end{tabular}
    \end{table}

    \begin{table}[H]
        \centering
        \caption{Resolución en tierra \(\Delta_{\text{ground}}\) – Sistema NIR (Sis.~6)}
        \label{tab:grd_nir_corrected}
        \begin{tabular}{|c|c|c|c|c|}
            \hline
            \rowcolor[HTML]{EFEFEF}
            \textbf{Canal} &
            \multicolumn{3}{c|}{\(\mathbf{\Delta_{\text{ground}}\,[\text{cm}]}\)} &
            \(\mathbf{\Delta_{\text{ground}}\,[\text{m}]}\) \\ \cline{2-4}
            \rowcolor[HTML]{EFEFEF}
            & 50 m & 1000 m & 5000 m & 5000 m \\ \hline
            Mono  & 4.12 & 82.57 & 411.79 & 4.12 \\ \hline
        \end{tabular}
    \end{table}
    %--------------------------------------------------------------

    %---------------------------------------------------------------
    \subsubsection{Comparison with Theoretical Resolution}
    \label{subsub:grd_comp}
    %---------------------------------------------------------------
    La Figura~\ref{fig:grd_comp} contrasta la resolución teórica
    (\(\Delta_{\text{ground,\,theo}}\), Tabla~\ref{tab:grd_fov_clean})
    con la experimental para los cortes a \(30\,\%\).
    Los valores experimentales del canal \(G\) (VIS) y del canal único (NIR) son los
    que más se aproximan a la especificación, con desviaciones absolutas
    inferiores a \(6\,\mathrm{mm}\) a \(50\,\mathrm{m}\)
    y relativas menores del \(7\,\%\) en todas las altitudes.

    % \begin{figure}[H]
    %     \centering
    %     \includegraphics[width=0.75\linewidth]{Figures/C4/grd_comparison.pdf}
    %     \caption{Comparación entre la resolución en tierra teórica y la medida.}
    %     \label{fig:grd_comp}
    % \end{figure}

    %---------------------------------------------------------------
    \subsubsection{Error Sources and Discrepancy Analysis}
    \label{subsub:grd_errors}
    %---------------------------------------------------------------
    Las diferencias observadas entre la especificación y la medición se asocian a:

    \begin{description}
      \item[Distorsión radial]  
            El modelo de tamaño de imagen supone proyección pinhole sin distorsión.
            Una distorsión barril del \(1\%\) desplaza la frecuencia de corte
            hasta un \(3\,\%\).
      \item[Paralaje en la medida de WD]  
            Un error sistemático de \(\pm1\,\mathrm{cm}\) en la distancia
            de trabajo introduce una incertidumbre del \(2.4\,\%\) en PMAG
            y, por tanto, en \(f_{\text{obj}}\).
      \item[Enfoque imperfecto]  
            Una desviación de solo \(10\,\mu\mathrm{m}\) en la posición
            del plano focal puede reducir la MTF de alta frecuencia
            entre \(5\) y \(8\,\%\).
      \item[Ruido y cuantización]  
            Aunque se promediaron 50 imágenes y se corrigió la corriente
            oscura (Sección~\ref{subsub:corriente_oscura_espectrometro}),
            el SNR limita la estimación de la ESF, añadiendo
            \(\approx2\,\%\) de dispersión a \(f_{\text{im}}\).
    \end{description}

    Una calibración geométrica por cámara-patrón y la
    compensación de distorsión de lente deberían reducir el sesgo relativo
    por debajo del \(3\,\%\).

    %---------------------------------------------------------------
    \subsubsection{Summary of MTF Findings}
    \label{subsub:grd_summary}
    %---------------------------------------------------------------
    \emph{En síntesis}:

    \begin{enumerate}
        \item El sistema VIS cumple el requisito de \(f_{\text{im}}\ge40\;\text{lp mm}^{-1}\)  
              en los tres canales; el canal \(G\) ofrece el mejor desempeño
              con \(79.4\;\text{lp mm}^{-1}\).
        \item El sistema NIR alcanza \(79.4\;\text{lp mm}^{-1}\), un \(34\,\%\)
              por debajo de la especificación, pero mantiene una
              resolución en tierra \(<3\,\text{cm}\) a \(50\,\text{m}\),
              suficiente para la misión.
        \item Las discrepancias con la teoría se deben, principalmente,
              a distorsión geométrica y a tolerancias de enfoque; ambas
              pueden mitigarse mediante calibración adicional.
        \item Para mejorar la concordancia,
              se propone añadir una etapa de rectificación geométrica
              antes de la extracción de la ESF y repetir la medición
              con iluminación de mayor contraste (4:1 según ISO 12233).
      \end{enumerate}


  \subsection{Respuesta espectral}
    \subsubsection{Curvas de sensibilidad}
      % → FIGURA: sensibilidad R, G, B y NIR normalizadas.
    \subsubsection{Linealidad y repetibilidad}
      % → Tabla: coeficiente $r$ entre repeticiones, desviación estadística.

\section{Síntesis y comparación con los requisitos}
  % → Resumen cruzado: requisito ↔ resultado ↔ % de cumplimiento.
  %   Discute los márgenes de mejora identificados.

\section{Lecciones aprendidas y trabajo futuro}
  % → Reflexiones sobre diseño, montaje, guiones de adquisición
  %   y posibles optimizaciones (p.ej. filtros más estrechos,
  %   firmware de cámara, compensación de vibraciones, IA en bordo).

% Opcional: anexos con listados de código, tablas de datos completos,
%           hojas de especificaciones de componentes ópticos, etc.
